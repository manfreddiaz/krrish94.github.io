---
layout: about
permalink: /
title: <strong>Krishna Murthy</strong> Jatavallabhula
description: PhD Student at <a href="https://mila.quebec/en/">Mila</a>, <a href="http://www.umontreal.ca/en/"> Universite de Montreal</a>

profile:
  align: rjight
  image: prof_pic.jpg

news: true
social: true
---


I am a second year PhD student at [Mila](https://mila.quebec/en/) (previously, Montreal Institute for Learning Algorithms), advised by [Dr. Liam Paull](https://people.csail.mit.edu/lpaull/). My interests are diverse; predominantly along the intersections of [deep learning](https://www.technologyreview.com/s/513696/deep-learning/), [computer vision](https://hayo.io/computer-vision/), and [autonomous robotics](https://en.wikipedia.org/wiki/Robotics).

At present, I devote most of my time to develop techniques that enable embodied agents _to not just see, but to understand_. Vision sensors like monocular and RGB-D cameras only provide a _robot_ information about what is visible to them. At a cognitive level though, algorithms must be able to leverage prior information about how the world works, and build useful representations. This is the hypothesis/motivation most of my current research hinges on. Indoor 3D mapping, scene understanding, and SLAM are some keywords I can classify my research under.

In the past, I worked on leveraging deep learning and tightly integrating it with *classical methods* for state estimation and prediction. Autonomous driving and 3D localization are two primary use-cases for my previous research.

When I'm not doing research, I love to spend time writing technical blogs, tutorials, and open-source code.
